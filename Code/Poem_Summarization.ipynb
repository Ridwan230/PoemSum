{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 791838,
          "sourceType": "datasetVersion",
          "datasetId": 1895
        },
        {
          "sourceId": 6704335,
          "sourceType": "datasetVersion",
          "datasetId": 3863979
        }
      ],
      "dockerImageVersionId": 30185,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Poem Summarization Code"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "4PzJAFMpH9lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show pytorch-lightning"
      ],
      "metadata": {
        "trusted": true,
        "id": "B7hKSH2UH9lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install --quiet pytorch-lightning"
      ],
      "metadata": {
        "trusted": true,
        "id": "XPTYezsuH9la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from transformers import AdamW, T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "id": "UmbNSUunH9la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('',encoding='utf8') #Enter location of the file poemsum_train.csv in the quotes\n",
        "valid_df = pd.read_csv('',encoding='utf8') #Enter location of the file poemsum_valid.csv in the quotes\n",
        "test_df = pd.read_csv('',encoding='utf8')  #Enter location of the file poemsum_test.csv in the quotes"
      ],
      "metadata": {
        "trusted": true,
        "id": "xkh1yQjMH9ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def clean_text(text):\n",
        "    # Remove extra white spaces and new lines\n",
        "    text = str(text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    # Remove non-alphanumeric and non-punctuation characters\n",
        "    text = re.sub('[^a-zA-Z0-9\\s{}]+'.format(re.escape(string.punctuation)), '', text)\n",
        "    # Strip leading/trailing white spaces\n",
        "    text = text.strip()\n",
        "    return text"
      ],
      "metadata": {
        "trusted": true,
        "id": "BsfseDpvH9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['cleaned_text'] = train_df['ctext'].apply(clean_text)\n",
        "train_df['text'] = train_df['text'].apply(clean_text)\n",
        "train_df['Title'] = train_df['Title'].apply(clean_text)\n",
        "\n",
        "valid_df['cleaned_text'] = valid_df['ctext'].apply(clean_text)\n",
        "valid_df['text'] = valid_df['text'].apply(clean_text)\n",
        "valid_df['Title'] = valid_df['Title'].apply(clean_text)\n",
        "\n",
        "test_df['cleaned_text'] = test_df['ctext'].apply(clean_text)\n",
        "test_df['text'] = test_df['text'].apply(clean_text)\n",
        "test_df['Title'] = test_df['Title'].apply(clean_text)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5UHt6AAiH9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all(title,ctext):\n",
        "    return title + \" - \" + ctext\n",
        "\n",
        "train_df['poem'] = train_df.apply(lambda x: get_all(x.Title, x.cleaned_text), axis=1)\n",
        "valid_df['poem'] = valid_df.apply(lambda x: get_all(x.Title, x.cleaned_text), axis=1)\n",
        "test_df['poem'] = test_df.apply(lambda x: get_all(x.Title, x.cleaned_text), axis=1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ydMo9vlNH9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['cleaned_text'].iloc[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "2HDq8IOUH9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['poem'].iloc[0]"
      ],
      "metadata": {
        "trusted": true,
        "id": "6TSfItGWH9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[['text','poem']]\n",
        "train_df.columns=[\"summary\", \"text\"]\n",
        "train_df=train_df.dropna()\n",
        "\n",
        "valid_df = valid_df[['text','poem']]\n",
        "valid_df.columns=[\"summary\", \"text\"]\n",
        "valid_df=valid_df.dropna()\n",
        "\n",
        "test_df = test_df[['text','poem']]\n",
        "test_df.columns=[\"summary\", \"text\"]\n",
        "test_df=test_df.dropna()"
      ],
      "metadata": {
        "trusted": true,
        "id": "PRq9MEgjH9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsSummaryDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: pd.DataFrame,\n",
        "        tokenizer: T5Tokenizer,\n",
        "        text_max_token_len: int = 512,\n",
        "        summary_max_token_len: int = 256):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = data\n",
        "        self.text_max_token_len = text_max_token_len\n",
        "        self.summary_max_token_len = summary_max_token_len\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index:int):\n",
        "        data_row = self.data.iloc[index]\n",
        "        text = data_row[\"text\"]\n",
        "\n",
        "        text_encoding = tokenizer(data_row[\"text\"],max_length=self.text_max_token_len,\n",
        "                                 padding=\"max_length\",\n",
        "                                 truncation=True,\n",
        "                                 return_attention_mask=True,\n",
        "                                 add_special_tokens=True,\n",
        "                                 return_tensors=\"pt\")\n",
        "\n",
        "        summary = data_row[\"summary\"]\n",
        "        summary_encoding = tokenizer(summary,max_length=self.summary_max_token_len,\n",
        "                                 padding=\"max_length\",\n",
        "                                 truncation=True,\n",
        "                                 return_attention_mask=True,\n",
        "                                 add_special_tokens=True,\n",
        "                                 return_tensors=\"pt\")\n",
        "\n",
        "        labels= summary_encoding[\"input_ids\"]\n",
        "        labels[labels == 0] = -100\n",
        "\n",
        "        return dict(\n",
        "            text=text,\n",
        "            summary=summary,\n",
        "            text_input_ids=text_encoding[\"input_ids\"].flatten(),\n",
        "            text_attention_mask=text_encoding[\"attention_mask\"].flatten(),\n",
        "            labels=labels.flatten(),\n",
        "            labels_attention_mask=summary_encoding[\"attention_mask\"].flatten())\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "5IiSIVmnH9lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsSummaryDataModule(pl.LightningDataModule):\n",
        "    def __init__(self,\n",
        "                train_df:pd.DataFrame,\n",
        "                test_df:pd.DataFrame,\n",
        "                tokenizer:T5Tokenizer,\n",
        "                batch_size: int = 8,\n",
        "                text_max_token_len: int = 512,\n",
        "                summary_max_token_len: int = 256):\n",
        "        super().__init__()\n",
        "        self.train_df=train_df\n",
        "        self.test_df=test_df\n",
        "\n",
        "        self.batch_size=batch_size\n",
        "        self.tokenizer=tokenizer\n",
        "        self.text_max_token_len=text_max_token_len\n",
        "        self.summary_max_token_len= summary_max_token_len\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset =  NewsSummaryDataset(\n",
        "            self.train_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len\n",
        "        )\n",
        "        self.test_dataset =  NewsSummaryDataset(\n",
        "            self.test_df,\n",
        "            self.tokenizer,\n",
        "            self.text_max_token_len,\n",
        "            self.summary_max_token_len\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=2)\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "tymswi-nH9lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW, T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer\n",
        "from transformers import BartTokenizerFast as BartTokenizer, BartForConditionalGeneration\n",
        "from transformers import ProphetNetForConditionalGeneration, ProphetNetTokenizer\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizerFast as PegasusTokenizer\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "MODEL_NAME = 't5-base'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FrcsmAMjH9lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 3\n",
        "BATCH_SIZE = 10\n",
        "\n",
        "data_module = NewsSummaryDataModule(train_df,valid_df,tokenizer,batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7U1gqRlVH9lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "678yMqGzH9lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsSummaryModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "\n",
        "    def forward(self, inputs_ids, attention_mask, decoder_attention_mask, labels=None):\n",
        "        output = self.model(inputs_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "                            labels=labels,\n",
        "                            decoder_attention_mask=decoder_attention_mask)\n",
        "        return output.loss, output.logits\n",
        "\n",
        "    def step(self, batch, batch_idx):\n",
        "        input_ids=batch[\"text_input_ids\"]\n",
        "        attention_mask = batch[\"text_attention_mask\"]\n",
        "        labels=batch[\"labels\"]\n",
        "        labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "        loss, outputs = self.forward(inputs_ids=input_ids,\n",
        "                             attention_mask=attention_mask,\n",
        "                             decoder_attention_mask=labels_attention_mask,\n",
        "                             labels=labels)\n",
        "        return loss, outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, outputs = self.step(batch, batch_idx)\n",
        "\n",
        "        self.log(\"train_loss\",loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, outputs = self.step(batch, batch_idx)\n",
        "        self.log(\"val_loss\",loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, outputs = self.step(batch, batch_idx)\n",
        "        self.log(\"test_loss\",loss, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=0.0001)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "LARLIxIRH9lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NewsSummaryModel()"
      ],
      "metadata": {
        "trusted": true,
        "id": "ygM01JX5H9lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "                        dirpath=\"checkpoints\",\n",
        "                        filename=\"best-checkpoint\",\n",
        "                        save_top_k=1,\n",
        "                        verbose=True,\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\")\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name=\"news-summary\")\n",
        "\n",
        "from pytorch_lightning.callbacks.progress import ProgressBar\n",
        "class LitProgressBar(ProgressBar):\n",
        "\n",
        "    def init_validation_tqdm(self):\n",
        "        bar = super().init_validation_tqdm()\n",
        "        bar.set_description('running validation ...')\n",
        "        bar.refresh_rate=30\n",
        "        return bar\n",
        "\n",
        "bar = LitProgressBar()\n",
        "\n",
        "trainer = pl.Trainer(logger=logger,\n",
        "                    enable_checkpointing=checkpoint_callback,\n",
        "                    max_epochs=N_EPOCHS,\n",
        "                    gpus=1,\n",
        "                    progress_bar_refresh_rate=30)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yJDPSnCxH9lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.fit(model,data_module)"
      ],
      "metadata": {
        "trusted": true,
        "id": "afLbzxi6H9lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = NewsSummaryModel.load_from_checkpoint(\n",
        "    trainer.checkpoint_callback.best_model_path\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "id": "C5oHqR7NH9lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available\")\n",
        "else:\n",
        "    print(\"CUDA is not available\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "eFy8J-r_H9lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(text):\n",
        "    # Check if CUDA is available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    # Move model and data to CUDA device if available\n",
        "    trained_model.to(device)\n",
        "\n",
        "    text_encoding = tokenizer(\n",
        "        text,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=True,\n",
        "        return_tensors='pt'\n",
        "        ).to(device)\n",
        "\n",
        "    generated_ids = trained_model.model.generate(\n",
        "        input_ids=text_encoding[\"input_ids\"],\n",
        "        attention_mask=text_encoding[\"attention_mask\"],\n",
        "        max_length=150,\n",
        "        num_beams=2,\n",
        "        repetition_penalty=2.5,\n",
        "        length_penalty=1.0,\n",
        "        early_stopping=True)\n",
        "\n",
        "    # Move generated IDs to CPU if CUDA is available\n",
        "    generated_ids = generated_ids.cpu()\n",
        "\n",
        "    preds = [\n",
        "        tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_id in generated_ids\n",
        "    ]\n",
        "    return \"\".join(preds)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "id": "ArJ-ZMLCH9lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['pred'] = test_df['text'].apply(summarize)"
      ],
      "metadata": {
        "trusted": true,
        "id": "8yN6S33LH9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('', index=False) #Enter name of the newly created predictions file in the quotes"
      ],
      "metadata": {
        "trusted": true,
        "id": "m5wf8IRcH9lq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}